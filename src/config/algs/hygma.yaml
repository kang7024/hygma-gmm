# --- HGCN-QMIX specific parameters ---

# use epsilon greedy action selector
action_selector: "epsilon_greedy"
epsilon_start: 1.0
epsilon_finish: 0.05
epsilon_anneal_time: 100000
evaluation_epsilon: 0.0

# Optimizer
optim_beta1: 0.9  # AdamW first moment coefficient
optim_beta2: 0.999  # AdamW second moment coefficient
optim_eps: 1e-8  # Small value for numerical stability
weight_decay: 0.01  # Weight decay

#runner: "parallel"
batch_size_run: 1 # Number of environments to run in parallel
runner: "episode"# Runs 1 env for an episode

mac: "hygma_mac"

use_rnn: True
batch_size: 128 # Number of episodes to train on
buffer_size: 5000 # Size of the replay buffer

# update the target network every {} episodes
target_update_interval: 200

# use the Q_Learner to train
agent_output_type: "q"
learner: "hgcn_learner"
double_q: True
mixer: "qmix"
mixing_embed_dim: 32
hypernet_layers: 2
hypernet_embed: 64

# Clustering related configuration
clustering_interval: 100000  # Check clustering every N timesteps
state_history_length: 5000  # State history length for clustering
behavior_history_length: 5000  # Behavior history length for clustering
stability_threshold: 0.6  # Keep existing grouping if less than 40% of agents need to move
min_clusters: 2
max_clusters: 3

# Fixed grouping
fix_grouping_steps: 2
fix_hgcn_steps: 2

# HGCN related configuration
#hgcn_in_dim: 96
#hidden_dim_scale: 1.0
hgcn_out_dim: 48
hgcn_hidden_dim: 64
hgcn_num_layers: 2

#init_agent_groups: [[0, 1, 2, 3, 4]]

# Loss hyperparameters
lambda_consistency: 0.001
lambda_attention: 0.01

name: "hygma"


